import uvicorn
from fastapi import FastAPI
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, JSONResponse
from pydantic import BaseModel
import requests
import os
from transformers import AutoProcessor, MusicgenForConditionalGeneration
import scipy.io.wavfile
from diffusers import StableDiffusionPipeline
import torch
from moviepy import *
import glob

# --- AIãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ (MusicGen) ---

print("ğŸµ MusicGenãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã‚’é–‹å§‹ã—ã¾ã™... (æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™)")
try:
    # ãƒ‡ãƒã‚¤ã‚¹ã®è‡ªå‹•é¸æŠ
    if torch.cuda.is_available():
        device = "cuda"
    elif torch.backends.mps.is_available():
        device = "mps"
    else:
        device = "cpu"
    print(f"Using device: {device}")
    
    model_id = "facebook/musicgen-small" 
    
    processor = AutoProcessor.from_pretrained(model_id)
    model = MusicgenForConditionalGeneration.from_pretrained(model_id).to(device)
    print("ğŸµ MusicGenãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰å®Œäº†")

except Exception as e:
    print(f"ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚{e}")
    model = None
    processor = None

# --- AIãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ (Stable Diffusion) ---
print("ğŸ¨ Stable Diffusionãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã‚’é–‹å§‹ã—ã¾ã™... (æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™)")
try:
    # ãƒ‡ãƒã‚¤ã‚¹ã®è‡ªå‹•é¸æŠ (MusicGenã¨å…±é€š)
    if torch.cuda.is_available():
        device = "cuda"
    elif torch.backends.mps.is_available():
        device = "mps"
    else:
        device = "cpu"
    print(f"Using device: {device}")
    
    # ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
    model_id = "runwayml/stable-diffusion-v1-5" 
    
    pipe = StableDiffusionPipeline.from_pretrained(
        model_id, 
        torch_dtype=torch.float16 if device == "cuda" else torch.float32 
        # â†‘ GPUãªã‚‰é«˜é€Ÿãªfloat16ã€CPUãªã‚‰float32
    ).to(device)
    
    print("ğŸ¨ Stable Diffusionãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰å®Œäº†")

except Exception as e:
    print(f"ã‚¨ãƒ©ãƒ¼: Stable Diffusionãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚{e}")
    pipe = None

VIDEO_DURATION_SECONDS = 8 # å‹•ç”»ã®é•·ã•ï¼ˆç§’ï¼‰
NUM_IMAGES = 5 # ç”Ÿæˆã™ã‚‹ç”»åƒã®æšæ•°
FPS = 24 # å‹•ç”»ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆ

# APIã‚­ãƒ¼
OPENWEATHER_API_KEY = "1b29095b72c45b44d310f5e55afd6c49"

# FastAPIã‚¢ãƒ—ãƒªã®åˆæœŸåŒ–
app = FastAPI()

app.mount("/static", StaticFiles(directory="static"), name="static")

# 1. å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®å‹å®šç¾©
class GenerationRequest(BaseModel):
    city: str
    text_prompt: str

# 2. OpenWeather APIã‹ã‚‰å¤©æ°—ã‚’å–å¾—ã™ã‚‹é–¢æ•°
def get_weather(city: str):
    """æŒ‡å®šã•ã‚ŒãŸéƒ½å¸‚ã®ç¾åœ¨ã®å¤©æ°—ã‚’å–å¾—ã™ã‚‹"""
    if not OPENWEATHER_API_KEY:
        print("ã‚¨ãƒ©ãƒ¼: OPENWEATHER_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        # ãƒ‡ãƒãƒƒã‚°ç”¨ã«ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
        return {"weather": [{"main": "Clear", "description": "clear sky"}], "main": {"temp": 25}}

    base_url = "http://api.openweathermap.org/data/2.5/weather"
    params = {
        "q": city,
        "appid": OPENWEATHER_API_KEY,
        "units": "metric", # æ¸©åº¦ã‚’æ‘‚æ°ï¼ˆâ„ƒï¼‰ã§å–å¾—
        "lang": "ja"      # æ—¥æœ¬èªã§å–å¾—
    }
    try:
        response = requests.get(base_url, params=params)
        response.raise_for_status() # HTTPã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Œã°ä¾‹å¤–ã‚’ç™ºç”Ÿ
        return response.json()
    except requests.exceptions.RequestException as e:
        print(f"APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return None

# 3. AIãƒ¢ãƒ‡ãƒ«ã®å‘¼ã³å‡ºã—
def run_musicgen(prompt: str, duration_seconds: int) -> str:
    """MusicGenã§éŸ³æ¥½ã‚’ç”Ÿæˆã™ã‚‹"""
    print(f"ğŸµ MusicGenå®Ÿè¡Œ: {prompt}")

    try:
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æº–å‚™
        inputs = processor(
            text=[prompt],
            padding=True,
            return_tensors="pt",
        ).to(device)
        
        # --- å‹•ç”»ã®é•·ã•ã«åˆã‚ã›ã¦ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¨ˆç®— ---
        # (ã“ã®å€¤ã¯ç›®å®‰ã§ã™ã€‚musicgen-small ã®å ´åˆ)
        tokens_per_second = 50 
        max_tokens = int(duration_seconds * tokens_per_second)  

        # éŸ³æ¥½ã‚’ç”Ÿæˆ 
        # ã‚‚ã£ã¨é•·ãã™ã‚‹å ´åˆã¯ max_new_tokens ã‚’å¢—ã‚„ã™ (ä¾‹: 1500 ã§ 30ç§’)
        audio_values = model.generate(**inputs, max_new_tokens=max_tokens) 
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        output_path = "static/music/generated_music.wav"
        sampling_rate = model.config.audio_encoder.sampling_rate
        
        # ãƒãƒƒãƒå‡¦ç†ï¼ˆä»Šå›ã¯1ã¤ï¼‰ã®æœ€åˆã®éŸ³å£°ã‚’å–å¾—
        audio_data = audio_values[0, 0].cpu().numpy()
        
        scipy.io.wavfile.write(output_path, rate=sampling_rate, data=audio_data)
        
        print(f"ğŸµ éŸ³æ¥½ã‚’ {output_path} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
        return output_path

    except Exception as e:
        print(f"MusicGenå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        return "static/music/error_music.wav" # ã‚¨ãƒ©ãƒ¼ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿”ã™
    
def run_stable_diffusion(prompt: str, num_images: int) -> list[str]:
    """Stable Diffusionã§ç”»åƒã‚’ç”Ÿæˆã™ã‚‹"""
    print(f"ğŸ¨ Stable Diffusionå®Ÿè¡Œ: {prompt}")
    
    if pipe is None:
        print("ã‚¨ãƒ©ãƒ¼: Stable Diffusionãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return [f"static/images/dummy_image_{i}.png" for i in range(num_images)]

    try:
        generated_paths = []
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ (ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚‚æŒ‡å®šã™ã‚‹ã¨å“è³ªãŒä¸ŠãŒã‚‹ã“ã¨ãŒå¤šã„)
        neg_prompt = "low quality, bad hands, blurry"
        
        # é«˜é€ŸåŒ–ã®ãŸã‚ã®è¨­å®š (GPUã®å ´åˆ)
        if device == "cuda":
            pipe.enable_model_cpu_offload() # ãƒ¡ãƒ¢ãƒªãŒå°‘ãªã„å ´åˆã«æœ‰åŠ¹
            # pipe.enable_xformers_memory_efficient_attention() # xformers ãŒã‚ã‚Œã°

        for i in range(num_images):
            # ç”»åƒã‚’ç”Ÿæˆ
            image = pipe(
                prompt=prompt, 
                negative_prompt=neg_prompt,
                num_inference_steps=20 # ã‚¹ãƒ†ãƒƒãƒ—æ•° (å°‘ãªã„ã¨é€Ÿã„ãŒè’ã„)
            ).images[0] # æœ€åˆã®ç”»åƒã‚’å–å¾—
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            output_path = f"static/images/generated_image_{i}.png"
            image.save(output_path)
            generated_paths.append(output_path)
            print(f"ğŸ¨ ç”»åƒ {i+1}/{num_images} ã‚’ {output_path} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
        
        return generated_paths

    except Exception as e:
        print(f"Stable Diffusionå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        return [f"static/images/error_image_{i}.png" for i in range(num_images)]    
    

def create_video(music_path: str, image_paths: list[str], duration: int) -> str:
    """MoviePyã‚’ä½¿ã£ã¦éŸ³æ¥½ã¨ç”»åƒã‚’å‹•ç”»ã«åˆæˆã™ã‚‹"""
    print("ğŸ¬ å‹•ç”»ã‚’ç”Ÿæˆä¸­ã§ã™...")
    output_video_path = "static/video/final_video.mp4"

    try:
        # 1. éŸ³æ¥½ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
        audio_clip = AudioFileClip(music_path)
        
        # éŸ³æ¥½ãŒæŒ‡å®šã—ãŸå‹•ç”»é•·ã‚ˆã‚ŠçŸ­ã„å ´åˆã€å‹•ç”»ã®é•·ã•ã‚’éŸ³æ¥½ã«åˆã‚ã›ã‚‹
        # (ã¾ãŸã¯ã€æŒ‡å®šã—ãŸé•·ã•ã§ã‚«ãƒƒãƒˆã™ã‚‹)
        final_duration = min(audio_clip.duration, duration)
        audio_clip = audio_clip.subclipped(0, final_duration)

        # 2. ç”»åƒã‹ã‚‰å‹•ç”»ã‚¯ãƒªãƒƒãƒ—ã‚’ä½œæˆ
        image_clips = []
        # 1æšã‚ãŸã‚Šã®è¡¨ç¤ºæ™‚é–“
        duration_per_image = final_duration / len(image_paths)

        for path in image_paths:
            # 0.5ç§’ã§ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¤ãƒ³/ã‚¢ã‚¦ãƒˆã™ã‚‹è¨­å®š
            img_clip = ImageClip(path).with_duration(duration_per_image).with_effects([vfx.FadeIn(0.5), vfx.FadeOut(0.5)])
            image_clips.append(img_clip)

        # 3. ç”»åƒã‚¯ãƒªãƒƒãƒ—ã‚’é †ç•ªã«é€£çµ
        video_clip = concatenate_videoclips(image_clips, method="compose")

        # 4. å‹•ç”»ã«éŸ³æ¥½ã‚’ã‚»ãƒƒãƒˆ
        final_video = video_clip.with_audio(audio_clip)

        # 5. MP4ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦æ›¸ãå‡ºã™
        final_video.write_videofile(
            output_video_path,
            codec='libx264',
            audio_codec='aac',
            fps=FPS 
        )
        
        print(f"ğŸ‰ å‹•ç”»ã‚’ {output_video_path} ã«ä¿å­˜ã—ã¾ã—ãŸï¼")
        return output_video_path

    except Exception as e:
        print(f"å‹•ç”»ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return "static/video/error_video.mp4" # ã‚¨ãƒ©ãƒ¼ç”¨ãƒ‘ã‚¹ (ãƒ€ãƒŸãƒ¼)
    
# 4. ãƒ¡ã‚¤ãƒ³ã®APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.post("/generate")
async def generate_media(request: GenerationRequest):
    """å¤©æ°—ã¨ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³æ¥½ã¨ç”»åƒã‚’ç”Ÿæˆã™ã‚‹"""
    
    # (a) å¤©æ°—ã‚’å–å¾—
    weather_data = get_weather(request.city)
    if not weather_data:
        return JSONResponse(status_code=500, content={"message": "å¤©æ°—æƒ…å ±ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚"})
        
    weather_main = weather_data.get("weather", [{}])[0].get("main", "Unknown") # 'Rain', 'Clear', 'Clouds' ãªã©
    weather_desc = weather_data.get("weather", [{}])[0].get("description", "unknown weather")
    temperature = weather_data.get("main", {}).get("temp", "N/A")

    print(f"å–å¾—ã—ãŸå¤©æ°—: {weather_main} ({weather_desc}), æ°—æ¸©: {temperature}â„ƒ")

    # (b) AIç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
    music_prompt = f"{weather_main}, {weather_desc}, {request.text_prompt}, cinematic music"
    image_prompt = f"A beautiful cinematic scene of {request.city} during {weather_main}, {request.text_prompt}, photorealistic, 4k"

    # (c) AIãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè¡Œ
    music_file_path = run_musicgen(music_prompt, duration_seconds=VIDEO_DURATION_SECONDS)
    image_file_paths = run_stable_diffusion(image_prompt, num_images=NUM_IMAGES)
    video_file_path = create_video(music_file_path, image_file_paths, VIDEO_DURATION_SECONDS)

    # (d) çµæœã‚’è¿”ã™
    return {
        "message": "ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼",
        "weather_info": f"{request.city}: {weather_desc}, {temperature}â„ƒ",
        "music_url": music_file_path,
        "image_urls": image_file_paths,
        "video_url": video_file_path,
        "prompts": {
            "music": music_prompt,
            "image": image_prompt
        }
    }

# 5. UIï¼ˆHTMLï¼‰ã‚’è¿”ã™ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.get("/", response_class=HTMLResponse)
async def get_ui():
    """ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã®HTMLã‚’è¿”ã™"""
    # å®Ÿéš›ã«ã¯index.htmlãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ã®ãŒè‰¯ã„ã§ã™
    with open("index.html", "r", encoding="utf-8") as f:
        html_content = f.read()
    return HTMLResponse(content=html_content)

# ã‚µãƒ¼ãƒãƒ¼ã®èµ·å‹• (ãƒ‡ãƒãƒƒã‚°ç”¨)
if __name__ == "__main__":
    # staticãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒãªã„å ´åˆã¯ä½œæˆ
    os.makedirs("static/music", exist_ok=True)
    os.makedirs("static/images", exist_ok=True)
    os.makedirs("static/video", exist_ok=True)
    
    uvicorn.run(app, host="127.0.0.1", port=8000)
